# .github/workflows/deploy-dev.yml
name: deploy-dev

on:
  push:
    branches: ['develop']    
  workflow_dispatch:        
    inputs:
      apply:
        description: "Start terraform apply (true/false)"
        required: false
        default: "true"
      backend_config:
        description: "Backend HCL file (default: backend-dev.hcl)"
        required: false
        default: "backend-dev.hcl"
      workspace:
        description: "Terraform workspace (default: dev)"
        required: false
        default: "dev"
      aws_region:
        description: "AWS region override (optional)"
        required: false
        default: "ap-southeast-2"
      trigger_destroy:
        description: "Run terraform destroy after completion (true/false)"
        required: false
        default: "false"

permissions:
  contents: read
  id-token: write
  security-events: write # Upload security scan result to Code Scanning
  actions: read

concurrency:
  group: terraform-${{ github.workflow }}-${{ github.ref_name }}
  cancel-in-progress: true

jobs:
  changes:
    name: Detect changes
    runs-on: ubuntu-latest
    outputs:
      code_changed: ${{ steps.classify.outputs.code_changed }}
      terraform_changed: ${{ steps.classify.outputs.terraform_changed }}
      should_run: ${{ steps.classify.outputs.should_run }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Detect changed files
        id: changed
        uses: tj-actions/changed-files@v45
        with:
          fetch_depth: 0

      - name: Classify changes
        id: classify
        shell: bash
        run: |
          set -euo pipefail

          code_changed="false"
          terraform_changed="false"

          files="${{ steps.changed.outputs.all_changed_files }}"
          if [ -n "$files" ]; then
            while IFS= read -r file; do
              case "$file" in
                *.tf|*.tfvars|*.tfvars.json|*.hcl|environments/*|locals.naming.tf)
                  terraform_changed="true"
                  ;;
              esac
              case "$file" in
                lambda/*|shared_resources/*|layers/*|scripts/*|docker/*|init.sh|build_cpp.sh|*.py|*.sh)
                  code_changed="true"
                  ;;
              esac
            done < <(printf '%s\n' "$files" | tr ' ' '\n')
          fi

          if [ "$code_changed" = "true" ] || [ "$terraform_changed" = "true" ]; then
            should_run="true"
          else
            should_run="false"
          fi

          {
            echo "code_changed=$code_changed"
            echo "terraform_changed=$terraform_changed"
            echo "should_run=$should_run"
          } >> "$GITHUB_OUTPUT"

          if [ "$should_run" = "true" ]; then
            echo "Detected changes - code: $code_changed, terraform: $terraform_changed"
          else
            echo "No code or terraform changes detected."
          fi

  deploy:
    name: Dev Plan/Deploy
    needs: changes
    if: needs.changes.outputs.should_run == 'true'
    runs-on: ubuntu-latest
    environment: dev

    env:
      AWS_REGION: ${{ (github.event_name == 'workflow_dispatch' && inputs.aws_region) || vars.AWS_REGION || 'ap-southeast-2' }}
      TF_WORKING_DIR: ${{ github.workspace }}/environments
      TARGET_WORKSPACE: ${{ (github.event_name == 'workflow_dispatch' && inputs.workspace) || 'dev' }}
      TF_BACKEND_CONFIG: ${{ (github.event_name == 'workflow_dispatch' && inputs.backend_config) || 'backend-dev.hcl' }}
      TF_IN_AUTOMATION: true
      TF_INPUT: false
      TF_VAR_region: ${{ (github.event_name == 'workflow_dispatch' && inputs.aws_region) || vars.AWS_REGION || 'ap-southeast-2' }}

      TF_APPLY_FLAG: ${{ (github.event_name == 'workflow_dispatch' && inputs.apply) || 'false' }}
      TF_DESTROY_FLAG: ${{ (github.event_name == 'workflow_dispatch' && inputs.trigger_destroy) || 'false' }}

      IMAGE_TAG: dev-${{ github.sha }}

      TF_VAR_beacon_admin_username: ${{ secrets.BEACON_ADMIN_USERNAME }}
      TF_VAR_beacon_admin_password: ${{ secrets.BEACON_ADMIN_PASSWORD }}
      TF_VAR_beacon_guest_username: ${{ secrets.BEACON_GUEST_USERNAME }}
      TF_VAR_beacon_guest_password: ${{ secrets.BEACON_GUEST_PASSWORD }}
      TF_VAR_azure_openai_api_key: ${{ secrets.AZURE_OPENAI_API_KEY }}
      TF_VAR_azure_openai_endpoint: ${{ secrets.AZURE_OPENAI_ENDPOINT }}
      TF_VAR_azure_openai_api_version: ${{ secrets.AZURE_OPENAI_API_VERSION }}
      TF_VAR_azure_openai_chat_deployment_name: ${{ secrets.AZURE_OPENAI_CHAT_DEPLOYMENT_NAME }}
      TF_VAR_openai_api_key: ${{ secrets.OPENAI_API_KEY }}
      PIPELINE_CODE_CHANGED: ${{ needs.changes.outputs.code_changed }}
      PIPELINE_TERRAFORM_CHANGED: ${{ needs.changes.outputs.terraform_changed }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install build toolchain
        run: |
          sudo apt-get update
          sudo apt-get install -y build-essential autoconf automake libtool pkg-config zlib1g-dev libcurl4-openssl-dev libbz2-dev liblzma-dev

      - name: Run init script
        run: |
          chmod +x ./init.sh
          ./init.sh
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.9.4

      - name: Prepare analytics shared assets
        if: ${{ env.PIPELINE_CODE_CHANGED == 'true' }}
        working-directory: lambda/analytics
        run: python docker_prep.py

      - name: Prepare askbeacon shared assets
        if: ${{ env.PIPELINE_CODE_CHANGED == 'true' }}
        working-directory: lambda/askbeacon
        run: python docker_prep.py

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}
      - name: Prepare Terraform plugin cache dir
        run: |
          echo "TF_PLUGIN_CACHE_DIR=$HOME/.terraform.d/plugin-cache" >> $GITHUB_ENV
          mkdir -p "$HOME/.terraform.d/plugin-cache"
      - name: Ensure ECR repos & import into Terraform
        run: |
          set -euo pipefail
          REGION="${{ env.AWS_REGION }}"
          WORKSPACE="${TARGET_WORKSPACE}"
          TF_DIR="${TF_WORKING_DIR}"

          terraform -chdir="${TF_DIR}" init -input=false -backend-config="${TF_BACKEND_CONFIG}"
          terraform -chdir="${TF_DIR}" workspace select "${WORKSPACE}" \
            || terraform -chdir="${TF_DIR}" workspace new "${WORKSPACE}"

          ACCOUNT_ID=$(aws sts get-caller-identity --query 'Account' --output text)

          declare -A MODULE_ADDRS=(
            ["analytics"]="module.serverless_beacon.module.docker_image_analytics_lambda.aws_ecr_repository.this[0]"
            ["askbeacon"]="module.serverless_beacon.module.docker_image_askbeacon_lambda.aws_ecr_repository.this[0]"
          )

          for kind in analytics askbeacon; do
            repo="sbeacon-${WORKSPACE}-${kind}-lambda-containers"

            if ! aws ecr describe-repositories --repository-names "$repo" --region "$REGION" >/dev/null 2>&1; then
              echo "Creating ECR repo: $repo"
              aws ecr create-repository \
                --repository-name "$repo" \
                --region "$REGION" \
                --image-scanning-configuration scanOnPush=true \
                --image-tag-mutability MUTABLE >/dev/null
              aws ecr put-lifecycle-policy \
                --repository-name "$repo" \
                --lifecycle-policy-text '{
                  "rules":[
                    {
                      "rulePriority":1,
                      "description":"Expire untagged after 7 days",
                      "selection":{"tagStatus":"untagged","countType":"sinceImagePushed","countUnit":"days","countNumber":7},
                      "action":{"type":"expire"}
                    },
                    {
                      "rulePriority":10,
                      "description":"Keep last 15 dev-/gh-/v tagged",
                      "selection":{"tagStatus":"tagged","tagPrefixList":["dev-","gh-","v"],"countType":"imageCountMoreThan","countNumber":15},
                      "action":{"type":"expire"}
                    }
                  ]
                }' >/dev/null || true
            else
              echo "ECR repo exists: $repo"
            fi

            name="sbeacon-${WORKSPACE}-${kind}-lambda-containers"
            addr="${MODULE_ADDRS[$kind]}"

            if ! terraform -chdir="${TF_DIR}" state show "$addr" >/dev/null 2>&1; then
              echo "Importing $name into Terraform state"
              terraform -chdir="${TF_DIR}" import "$addr" "$name"
            else
              echo "Terraform already tracks $name, skip import"
            fi
          done
        
      - name: Docker Buildx
        if: ${{ env.PIPELINE_CODE_CHANGED == 'true' }}
        uses: docker/setup-buildx-action@v3

      - name: Cache docker layers
        if: ${{ env.PIPELINE_CODE_CHANGED == 'true' }}
        uses: actions/cache@v4
        with:
          path: /tmp/.buildx-cache
          key: ${{ runner.os }}-buildx-${{ github.sha }}
          restore-keys: ${{ runner.os }}-buildx-

      - name: ECR Login
        if: ${{ env.PIPELINE_CODE_CHANGED == 'true' }}
        id: ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Build & Push analytics image
        if: ${{ env.PIPELINE_CODE_CHANGED == 'true' }}
        uses: docker/build-push-action@v6
        with:
          context: ./lambda/analytics
          push: true
          tags: |
            ${{ steps.ecr.outputs.registry }}/sbeacon-${{ env.TARGET_WORKSPACE }}-analytics-lambda-containers:${{ env.IMAGE_TAG }}
          cache-from: type=local,src=/tmp/.buildx-cache
          cache-to: type=local,dest=/tmp/.buildx-cache-new

      - name: Scan analytics image with Trivy (It should fail on HIGH/CRITICAL)
        if: ${{ env.PIPELINE_CODE_CHANGED == 'true' }}
        id: scan_analytics
        continue-on-error: true           # Allow run next image vul scan
        uses: aquasecurity/trivy-action@0.24.0
        with:
          image-ref: ${{ steps.ecr.outputs.registry }}/sbeacon-${{ env.TARGET_WORKSPACE }}-analytics-lambda-containers:${{ env.IMAGE_TAG }}
          format: 'table'
          output: 'trivy-analytics.txt'
          vuln-type: 'os,library'
          severity: 'CRITICAL,HIGH'
          exit-code: '0'   # Warning: Now Image with vuls can be deployed, change to "1" after testing !!! 
          ignore-unfixed: true
          timeout: '10m'

      - name: Attach analytics report to summary
        if: ${{ env.PIPELINE_CODE_CHANGED == 'true' && always() && steps.scan_analytics.outcome != 'skipped' }}
        run: |
          echo '### Analytics Image Trivy Reports: ' >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          tail -n 200 trivy-analytics.txt >> $GITHUB_STEP_SUMMARY # Last 200 records
          echo '```' >> $GITHUB_STEP_SUMMARY

      - name: Upload analytics report artifact
        if: ${{ env.PIPELINE_CODE_CHANGED == 'true' && always() && steps.scan_analytics.outcome != 'skipped' }}
        uses: actions/upload-artifact@v4
        with:
          name: trivy-analytics-${{ github.run_id }}
          path: trivy-analytics.txt

      - name: Build & Push askbeacon image
        if: ${{ env.PIPELINE_CODE_CHANGED == 'true' }}
        uses: docker/build-push-action@v6
        with:
          context: ./lambda/askbeacon
          push: true
          tags: |
            ${{ steps.ecr.outputs.registry }}/sbeacon-${{ env.TARGET_WORKSPACE }}-askbeacon-lambda-containers:${{ env.IMAGE_TAG }}
          cache-from: type=local,src=/tmp/.buildx-cache
          cache-to: type=local,dest=/tmp/.buildx-cache-new

      - name: Scan askbeacon image with Trivy (It should fail on HIGH/CRITICAL)
        if: ${{ env.PIPELINE_CODE_CHANGED == 'true' }}
        id: scan_askbeacon
        continue-on-error: true
        uses: aquasecurity/trivy-action@0.24.0
        with:
          image-ref: ${{ steps.ecr.outputs.registry }}/sbeacon-${{ env.TARGET_WORKSPACE }}-askbeacon-lambda-containers:${{ env.IMAGE_TAG }}
          format: 'table'
          output: 'trivy-askbeacon.txt'
          vuln-type: 'os,library'
          severity: 'CRITICAL,HIGH'
          exit-code: '0' # Warning: Now Image with vuls can be deployed, change to "1" after testing !!! 
          ignore-unfixed: true
          timeout: '10m'

      - name: Attach askbeacon report to summary
        if: ${{ env.PIPELINE_CODE_CHANGED == 'true' && always() && steps.scan_askbeacon.outcome != 'skipped' }}
        run: |
          echo '### Askbeacon Image Trivy Reports: ' >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          tail -n 200 trivy-askbeacon.txt >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY

      - name: Upload askbeacon report artifact
        if: ${{ env.PIPELINE_CODE_CHANGED == 'true' && always() && steps.scan_askbeacon.outcome != 'skipped' }}
        uses: actions/upload-artifact@v4
        with:
          name: trivy-askbeacon-${{ github.run_id }}
          path: trivy-askbeacon.txt

      - name: Gate - It should fail if any image on HIGH/CRITICAL
        if: ${{ env.PIPELINE_CODE_CHANGED == 'true' && always() }}
        run: |
          a="${{ steps.scan_analytics.outcome }}"
          b="${{ steps.scan_askbeacon.outcome }}"
          echo "analytics=${a}, askbeacon=${b}"
          if [ "$a" = "failure" ] || [ "$b" = "failure" ]; then
            echo "::error::HIGH/CRITICAL Vulnerabilities Alerts."
            exit 1
          fi

      - name: Move layer cache
        if: ${{ env.PIPELINE_CODE_CHANGED == 'true' }}
        run: |
          rm -rf /tmp/.buildx-cache
          mv /tmp/.buildx-cache-new /tmp/.buildx-cache

      - name: Resolve ECR digests for dev tag
        if: ${{ env.PIPELINE_CODE_CHANGED == 'true' }}
        id: digests
        shell: bash
        run: |
          set -euo pipefail
          TAG="${IMAGE_TAG}"

          get_digest () {
            local repo="$1"
            aws ecr describe-images \
              --repository-name "$repo" \
              --image-ids imageTag="$TAG" \
              --query 'imageDetails[0].imageDigest' \
              --output text
          }

          ANALYTICS_REPO="sbeacon-${TARGET_WORKSPACE}-analytics-lambda-containers"
          ASKBEACON_REPO="sbeacon-${TARGET_WORKSPACE}-askbeacon-lambda-containers"

          ANALYTICS_DIGEST="$(get_digest "$ANALYTICS_REPO")"
          ASKBEACON_DIGEST="$(get_digest "$ASKBEACON_REPO")"

          if [ -z "$ANALYTICS_DIGEST" ] || [ "$ANALYTICS_DIGEST" = "None" ]; then
            echo "::error::analytics image not found for tag $TAG"; exit 1
          fi
          if [ -z "$ASKBEACON_DIGEST" ] || [ "$ASKBEACON_DIGEST" = "None" ]; then
            echo "::error::askbeacon image not found for tag $TAG"; exit 1
          fi

          ACCOUNT_ID=$(aws sts get-caller-identity --query 'Account' --output text)
          REG="${ACCOUNT_ID}.dkr.ecr.${{ env.AWS_REGION }}.amazonaws.com"

          echo "TF_VAR_analytics_lambda_image_uri=${REG}/${ANALYTICS_REPO}@${ANALYTICS_DIGEST}" >> $GITHUB_ENV
          echo "TF_VAR_askbeacon_lambda_image_uri=${REG}/${ASKBEACON_REPO}@${ASKBEACON_DIGEST}" >> $GITHUB_ENV



      - name: Cache Terraform plugins & .terraform
        uses: actions/cache@v4
        with:
          path: |
            ~/.terraform.d/plugin-cache
            ${{ env.TF_WORKING_DIR }}/.terraform
          key: ${{ runner.os }}-tf-${{ hashFiles('**/*.tf','**/*.tfvars','**/*.hcl') }}
          restore-keys: ${{ runner.os }}-tf-

      - name: Terraform Init
        run: terraform -chdir=${{ env.TF_WORKING_DIR }} init -input=false -upgrade -backend-config=${{ env.TF_BACKEND_CONFIG }}

      - name: Select Terraform Workspace
        run: terraform -chdir=${{ env.TF_WORKING_DIR }} workspace select ${{ env.TARGET_WORKSPACE }} || terraform -chdir=${{ env.TF_WORKING_DIR }} workspace new ${{ env.TARGET_WORKSPACE }}

      - name: Terraform Validate
        run: terraform -chdir=${{ env.TF_WORKING_DIR }} validate

      - name: IaC scan (Terraform) with Trivy config
        id: trivy_iac
        continue-on-error: true
        uses: aquasecurity/trivy-action@0.24.0
        with:
          scan-type: 'config'
          scan-ref: './environments'
          format: 'table'
          output: 'trivy-iac.txt'
          severity: 'CRITICAL,HIGH'
          exit-code: '0' # Warning: Now IaC with vuls can be deployed, change to "1" after testing !!! 
          timeout: '5m'

      - name: Attach IaC scan to summary
        if: always() && steps.trivy_iac.outcome != 'skipped'
        run: |
          echo '### Trivy IaC (Terraform) report' >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          tail -n 200 trivy-iac.txt >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY

      - name: Upload IaC report artifact
        if: always() && steps.trivy_iac.outcome != 'skipped'
        uses: actions/upload-artifact@v4
        with:
          name: trivy-iac-${{ github.run_id }}
          path: trivy-iac.txt

      - name: Gate - It should fail if IaC has HIGH/CRITICAL
        if: ${{ steps.trivy_iac.outcome == 'failure' }}
        run: |
          echo "::error::Trivy IaC scan found HIGH/CRITICAL."
          exit 1

      - name: Terraform Plan
        id: plan
        run: |
          terraform -chdir=${{ env.TF_WORKING_DIR }} plan -input=false -lock-timeout=10m -out=tfplan
          terraform -chdir=${{ env.TF_WORKING_DIR }} show -no-color tfplan > ${{ env.TF_WORKING_DIR }}/tfplan.txt

      - name: Upload Plan
        uses: actions/upload-artifact@v4
        with:
          name: dev-terraform-plan-${{ github.run_id }}
          path: ${{ env.TF_WORKING_DIR }}/tfplan.txt

      - name: Terraform Apply
        run: terraform -chdir=${{ env.TF_WORKING_DIR }} apply -input=false -lock-timeout=10m -auto-approve tfplan

      - name: Publish API URL
        if: env.TF_DESTROY_FLAG != 'true'
        shell: bash
        run: |
          set -euo pipefail
          # Get JSON output, filtering stderr warnings
          json_output=$(terraform -chdir=${{ env.TF_WORKING_DIR }} output -json api_url 2>/dev/null || echo "")
          if [ -z "${json_output}" ]; then
            echo "::error::Failed to get terraform output 'api_url'. Output may not exist yet."
            terraform -chdir=${{ env.TF_WORKING_DIR }} output 2>&1 || true
            exit 1
          fi
          # Extract value from JSON (format: {"value": "...", "type": "string"})
          url=$(echo "${json_output}" | python3 -c "import sys, json; data = json.load(sys.stdin); value = data.get(\"value\", \"\") if isinstance(data, dict) else \"\"; print(value) if value and value != \"null\" else exit(1)" || echo "")
          if [ -z "${url}" ]; then
            echo "::error::terraform output 'api_url' is empty or null."
            echo "JSON output: ${json_output}"
            exit 1
          fi
          echo "Discovered API URL: ${url}"
          echo "SMOKE_URL=${url}" >> $GITHUB_ENV
          aws ssm put-parameter \
            --name "/serverless-beacon/${{ env.TARGET_WORKSPACE }}/api_url" \
            --value "${url}" \
            --type String \
            --overwrite \
            --region "${{ env.AWS_REGION }}"

      - name: Smoke test API
        if: env.TF_DESTROY_FLAG != 'true'
        shell: bash
        run: |
          set -euo pipefail
          EXTRA=()
          # Get JSON output, filtering stderr warnings
          json_output=$(terraform -chdir=${{ env.TF_WORKING_DIR }} output -json admin_login_command 2>/dev/null || echo "")
          if [ -n "${json_output}" ]; then
            login_cmd=$(echo "${json_output}" | python3 -c "import sys, json; data = json.load(sys.stdin); value = data.get(\"value\", \"\") if isinstance(data, dict) else \"\"; print(value) if value and value != \"null\" and value != \"N/A\" else exit(1)" || echo "")
            if [ -n "${login_cmd}" ] && [ "${login_cmd}" != "N/A" ]; then
              token=$(eval "${login_cmd}")
              token=$(echo "${token}" | tr -d '"')
              if [ -n "${token}" ]; then
                EXTRA+=(--bearer-token "${token}")
              fi
            fi
          fi
          python scripts/health_check.py \
            --url "${SMOKE_URL}" \
            --expected-status 200 \
            --retries 5 \
            --timeout 10 \
            --backoff 2 \
            "${EXTRA[@]}"

      - name: Confirm destroy
        if: env.TF_DESTROY_FLAG == 'true'
        uses: trstringer/manual-approval@v1
        with:
          approvers: ${{ github.actor }}
          secret: ${{ secrets.GITHUB_TOKEN }}
          issue-title: 'Manual Deploy - Destroy Confirmation'
          issue-body: 'Confirm terraform destroy for workspace `${{ env.TARGET_WORKSPACE }}`'
          exclude-workflow-initiator-as-approver: false
          fail-on-denial: true

      - name: Terraform Destroy
        if: env.TF_DESTROY_FLAG == 'true'
        run: terraform -chdir=${{ env.TF_WORKING_DIR }} destroy -input=false -lock-timeout=10m -auto-approve

      - name: Clean up plan files
        if: always()
        run: rm -f ${{ env.TF_WORKING_DIR }}/tfplan ${{ env.TF_WORKING_DIR }}/tfplan.txt

  no-deploy:
    name: Skip deployment
    needs: changes
    runs-on: ubuntu-latest
    if: needs.changes.outputs.should_run != 'true'
    steps:
      - name: No changes detected
        run: echo "No code or Terraform changes detected. Skipping deployment."

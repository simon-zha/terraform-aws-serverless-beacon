name: deploy-prod

on:
  push:
    tags:
      - 'v*.*.*'      
  workflow_dispatch:
    inputs:
      tag:
        description: 'Stable tag to deploy in the prod environment (e.g., v1.2.3).'
        required: false
        type: string

permissions:
  contents: read
  id-token: write
  issues: write
  pull-requests: write
  security-events: write # Upload security scan result to Code Scanning

concurrency:
  group: production-deploy
  cancel-in-progress: true

jobs:
  changes:
    name: Detect changes
    runs-on: ubuntu-latest
    outputs:
      code_changed: ${{ steps.classify.outputs.code_changed }}
      terraform_changed: ${{ steps.classify.outputs.terraform_changed }}
      should_run: ${{ steps.classify.outputs.should_run }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Detect changed files
        id: changed
        uses: tj-actions/changed-files@v45
        with:
          fetch_depth: 0

      - name: Classify changes
        id: classify
        shell: bash
        run: |
          set -euo pipefail

          code_changed="false"
          terraform_changed="false"

          files="${{ steps.changed.outputs.all_changed_files }}"
          if [ -n "$files" ]; then
            while IFS= read -r file; do
              case "$file" in
                *.tf|*.tfvars|*.tfvars.json|*.hcl|environments/*|locals.naming.tf)
                  terraform_changed="true"
                  ;;
              esac
              case "$file" in
                lambda/*|shared_resources/*|layers/*|scripts/*|docker/*|init.sh|build_cpp.sh|*.py|*.sh)
                  code_changed="true"
                  ;;
              esac
            done < <(printf '%s\n' "$files" | tr ' ' '\n')
          fi

          if [ "$code_changed" = "true" ] || [ "$terraform_changed" = "true" ]; then
            should_run="true"
          else
            should_run="false"
          fi

          {
            echo "code_changed=$code_changed"
            echo "terraform_changed=$terraform_changed"
            echo "should_run=$should_run"
          } >> "$GITHUB_OUTPUT"

          if [ "$should_run" = "true" ]; then
            echo "Detected changes - code: $code_changed, terraform: $terraform_changed"
          else
            echo "No code or terraform changes detected."
          fi

  deploy:
    runs-on: ubuntu-latest
    needs: changes
    if: needs.changes.outputs.should_run == 'true'
    environment: prod

    env:
      AWS_REGION: ${{ vars.AWS_REGION || 'ap-southeast-2' }}
      TF_WORKING_DIR: ${{ github.workspace }}/environments
      TARGET_WORKSPACE: 'prod'
      TF_BACKEND_CONFIG: 'backend-prod.hcl'
      TF_IN_AUTOMATION: true
      TF_INPUT: false
      TF_VAR_region: ${{ vars.AWS_REGION || 'ap-southeast-2' }}

      TF_VAR_beacon_admin_username: ${{ secrets.BEACON_ADMIN_USERNAME }}
      TF_VAR_beacon_admin_password: ${{ secrets.BEACON_ADMIN_PASSWORD }}
      TF_VAR_beacon_guest_username: ${{ secrets.BEACON_GUEST_USERNAME }}
      TF_VAR_beacon_guest_password: ${{ secrets.BEACON_GUEST_PASSWORD }}
      TF_VAR_azure_openai_api_key: ${{ secrets.AZURE_OPENAI_API_KEY }}
      TF_VAR_azure_openai_endpoint: ${{ secrets.AZURE_OPENAI_ENDPOINT }}
      TF_VAR_azure_openai_api_version: ${{ secrets.AZURE_OPENAI_API_VERSION }}
      TF_VAR_azure_openai_chat_deployment_name: ${{ secrets.AZURE_OPENAI_CHAT_DEPLOYMENT_NAME }}
      TF_VAR_openai_api_key: ${{ secrets.OPENAI_API_KEY }}
      PIPELINE_CODE_CHANGED: ${{ needs.changes.outputs.code_changed }}
      PIPELINE_TERRAFORM_CHANGED: ${{ needs.changes.outputs.terraform_changed }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Resolve stable tag
        id: ver
        shell: bash
        run: |
          set -euo pipefail
          TAG_INPUT="${{ inputs.tag || '' }}"
          if [ -n "$TAG_INPUT" ]; then
            TAG="$TAG_INPUT"
          else
            TAG="${GITHUB_REF_NAME:-}"
          fi
          if [ -z "$TAG" ]; then
            echo "::error::No tag provided/found."; exit 1
          fi
          if echo "$TAG" | grep -q -- '-rc\.'; then
            echo "::error::This job deploys STABLE tags only (got '$TAG'). Run Promote RC to Stable first."; exit 1
          fi
          echo "tag=$TAG" >> "$GITHUB_OUTPUT"

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Ensure backend S3 bucket & DynamoDB table from backend-prod.hcl
        shell: bash
        run: |
          set -euo pipefail
          CFG="${{ env.TF_WORKING_DIR }}/${{ env.TF_BACKEND_CONFIG }}"

          if [ ! -f "$CFG" ]; then
            echo "::error::Backend config file not found: $CFG"; exit 1
          fi

          get_val () { sed -nE "s/^[[:space:]]*$1[[:space:]]*=[[:space:]]*\"([^\"]+)\".*/\1/p" "$CFG" | head -1; }

          BUCKET="$(get_val bucket)"
          REGION_CFG="$(get_val region)"
          TABLE="$(get_val dynamodb_table)"

          [ -z "$BUCKET" ] && { echo "::error::bucket not found in $CFG"; exit 1; }
          [ -z "$REGION_CFG" ] && REGION_CFG="${AWS_REGION}"
          [ -z "$TABLE" ] && echo "No dynamodb_table in backend config (ok, will skip DDB)."

          echo "Backend bucket: $BUCKET (region: $REGION_CFG)"
          echo "DynamoDB table: ${TABLE:-<none>}"
          if aws s3api head-bucket --bucket "$BUCKET" 2>/dev/null; then
            echo "S3 bucket exists: $BUCKET"
          else
            echo "Creating S3 bucket: $BUCKET"
            if [ "$REGION_CFG" = "us-east-1" ]; then
              aws s3api create-bucket --bucket "$BUCKET" >/dev/null
            else
              aws s3api create-bucket --bucket "$BUCKET" \
                --create-bucket-configuration LocationConstraint="$REGION_CFG" >/dev/null
            fi
            aws s3api put-bucket-versioning --bucket "$BUCKET" --versioning-configuration Status=Enabled >/dev/null || true
            aws s3api put-bucket-encryption --bucket "$BUCKET" --server-side-encryption-configuration \
              '{"Rules":[{"ApplyServerSideEncryptionByDefault":{"SSEAlgorithm":"AES256"}}]}' >/dev/null || true
          fi

          # DynamoDB lock table
          if [ -n "${TABLE:-}" ]; then
            if aws dynamodb describe-table --table-name "$TABLE" >/dev/null 2>&1; then
              echo "DynamoDB table exists: $TABLE"
            else
              echo "Creating DynamoDB table: $TABLE"
              aws dynamodb create-table \
                --table-name "$TABLE" \
                --attribute-definitions AttributeName=LockID,AttributeType=S \
                --key-schema AttributeName=LockID,KeyType=HASH \
                --billing-mode PAY_PER_REQUEST >/dev/null
              aws dynamodb wait table-exists --table-name "$TABLE"
            fi
          fi

      - name: Prepare Terraform plugin cache dir
        run: |
          echo "TF_PLUGIN_CACHE_DIR=$HOME/.terraform.d/plugin-cache" >> $GITHUB_ENV
          mkdir -p "$HOME/.terraform.d/plugin-cache"

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.9.4

      - name: Terraform Init (for import/state)
        run: terraform -chdir=${{ env.TF_WORKING_DIR }} init -input=false -upgrade -backend-config=${{ env.TF_BACKEND_CONFIG }}

      - name: Select/Create Workspace
        run: terraform -chdir=${{ env.TF_WORKING_DIR }} workspace select ${{ env.TARGET_WORKSPACE }} || terraform -chdir=${{ env.TF_WORKING_DIR }} workspace new ${{ env.TARGET_WORKSPACE }}

      - name: Ensure PROD ECR repos & import into Terraform
        shell: bash
        run: |
          set -euo pipefail
          REGION="${{ env.AWS_REGION }}"
          WORKSPACE="${{ env.TARGET_WORKSPACE }}"
          TF_DIR="${{ env.TF_WORKING_DIR }}"

          declare -A MODULE_ADDRS=(
            ["analytics"]="module.serverless_beacon.module.docker_image_analytics_lambda.aws_ecr_repository.this[0]"
            ["askbeacon"]="module.serverless_beacon.module.docker_image_askbeacon_lambda.aws_ecr_repository.this[0]"
          )

          for kind in analytics askbeacon; do
            repo="sbeacon-${WORKSPACE}-${kind}-lambda-containers"

            if ! aws ecr describe-repositories --repository-names "$repo" --region "$REGION" >/dev/null 2>&1; then
              echo "Creating ECR repo: $repo"
              aws ecr create-repository \
                --repository-name "$repo" \
                --region "$REGION" \
                --image-scanning-configuration scanOnPush=true \
                --image-tag-mutability MUTABLE >/dev/null
            else
              echo "ECR repo exists: $repo"
            fi

            addr="${MODULE_ADDRS[$kind]}"
            if ! terraform -chdir="${TF_DIR}" state show "$addr" >/dev/null 2>&1; then
              echo "Importing $repo into Terraform state"
              terraform -chdir="${TF_DIR}" import "$addr" "$repo"
            else
              echo "Terraform already tracks $repo, skip import"
            fi
          done

      - name: ECR Login
        uses: aws-actions/amazon-ecr-login@v2

      - name: Verify PROD images exist for the stable tag
        id: digests
        shell: bash
        run: |
          set -euo pipefail
          TAG="${{ steps.ver.outputs.tag }}"
          ACCOUNT_ID=$(aws sts get-caller-identity --query 'Account' --output text)
          REG="${ACCOUNT_ID}.dkr.ecr.${{ env.AWS_REGION }}.amazonaws.com"

          get_digest () {
            local repo="$1"
            aws ecr describe-images \
              --repository-name "$repo" \
              --image-ids imageTag="$TAG" \
              --query 'imageDetails[0].imageDigest' --output text
          }

          A_REPO="sbeacon-prod-analytics-lambda-containers"
          B_REPO="sbeacon-prod-askbeacon-lambda-containers"

          A_DIGEST="$(get_digest "$A_REPO")"
          B_DIGEST="$(get_digest "$B_REPO")"

          if [ -z "$A_DIGEST" ] || [ "$A_DIGEST" = "None" ] || [ -z "$B_DIGEST" ] || [ "$B_DIGEST" = "None" ]; then
            echo "::error::Stable images not found in PROD ECR for tag '$TAG'. Run the 'Promote RC to Stable & Release' workflow first to copy/retag images from STAGING -> PROD."
            exit 1
          fi

          echo "TF_VAR_analytics_lambda_image_uri=${REG}/${A_REPO}@${A_DIGEST}" >> $GITHUB_ENV
          echo "TF_VAR_askbeacon_lambda_image_uri=${REG}/${B_REPO}@${B_DIGEST}" >> $GITHUB_ENV

          echo "registry=$REG" >> "$GITHUB_OUTPUT"
          echo "analytics_digest=$A_DIGEST" >> "$GITHUB_OUTPUT"
          echo "askbeacon_digest=$B_DIGEST" >> "$GITHUB_OUTPUT"


      - name: Set up Python (for docker_prep.py)
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install build toolchain
        run: |
          sudo apt-get update
          sudo apt-get install -y build-essential autoconf automake libtool pkg-config zlib1g-dev libcurl4-openssl-dev libbz2-dev liblzma-dev

      - name: Run init script
        run: |
          chmod +x ./init.sh
          ./init.sh

      - name: Prepare analytics shared assets
        if: ${{ env.PIPELINE_CODE_CHANGED == 'true' }}
        working-directory: lambda/analytics
        run: python docker_prep.py

      - name: Prepare askbeacon shared assets
        if: ${{ env.PIPELINE_CODE_CHANGED == 'true' }}
        working-directory: lambda/askbeacon
        run: python docker_prep.py

      - name: Terraform Validate
        run: terraform -chdir=${{ env.TF_WORKING_DIR }} validate

      - name: IaC scan (Terraform) with Trivy config
        id: trivy_iac
        continue-on-error: true
        uses: aquasecurity/trivy-action@0.24.0
        with:
          scan-type: 'config'
          scan-ref: './environments'
          format: 'table'
          output: 'trivy-iac.txt'
          severity: 'CRITICAL,HIGH'
          exit-code: '0' # Warning: Now IaC with vuls can be deployed, change to "1" after testing !!! 
          timeout: '5m'

      - name: Attach IaC scan to summary
        if: always() && steps.trivy_iac.outcome != 'skipped'
        run: |
          echo '### Trivy IaC (Terraform) report' >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          tail -n 200 trivy-iac.txt >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY

      - name: Upload IaC report artifact
        if: always() && steps.trivy_iac.outcome != 'skipped'
        uses: actions/upload-artifact@v4
        with:
          name: trivy-iac-${{ github.run_id }}
          path: trivy-iac.txt

      - name: Gate - It should fail if IaC has HIGH/CRITICAL
        if: ${{ steps.trivy_iac.outcome == 'failure' }}
        run: |
          echo "::error::Trivy IaC scan found HIGH/CRITICAL."
          exit 1

      - name: Terraform Plan
        id: plan
        run: |
          terraform -chdir=${{ env.TF_WORKING_DIR }} plan -input=false -lock-timeout=10m -out=tfplan
          terraform -chdir=${{ env.TF_WORKING_DIR }} show -no-color tfplan > ${{ env.TF_WORKING_DIR }}/tfplan.txt

      - name: Upload Plan
        uses: actions/upload-artifact@v4
        with:
          name: prod-terraform-plan-${{ github.run_id }}
          path: ${{ env.TF_WORKING_DIR }}/tfplan.txt

      - name: Confirm production apply
        uses: trstringer/manual-approval@v1
        with:
          approvers: ${{ github.actor }}
          secret: ${{ secrets.GITHUB_TOKEN }}
          issue-title: 'Prod apply approval for ${{ steps.ver.outputs.tag }}'
          issue-body: 'Confirm terraform apply for prod with tag `${{ steps.ver.outputs.tag }}`'
          exclude-workflow-initiator-as-approver: false
          fail-on-denial: true

      - name: Terraform Apply
        run: terraform -chdir=${{ env.TF_WORKING_DIR }} apply -input=false -lock-timeout=10m -auto-approve tfplan

      - name: Publish API URL
        shell: bash
        run: |
          set -euo pipefail
          url=$(terraform -chdir=${{ env.TF_WORKING_DIR }} output -raw api_url)
          if [ -z "${url}" ]; then
            echo "::error::terraform output 'api_url' is empty."
            exit 1
          fi
          echo "Discovered API URL: ${url}"
          echo "SMOKE_URL=${url}" >> $GITHUB_ENV
          aws ssm put-parameter \
            --name "/serverless-beacon/${{ env.TARGET_WORKSPACE }}/api_url" \
            --value "${url}" \
            --type String \
            --overwrite \
            --region "${{ env.AWS_REGION }}"

      - name: Smoke test API
        shell: bash
        run: |
          set -euo pipefail
          EXTRA=()
          login_cmd=$(terraform -chdir=${{ env.TF_WORKING_DIR }} output -raw admin_login_command)
          if [ "${login_cmd}" != "N/A" ]; then
            token=$(eval "${login_cmd}")
            token=$(echo "${token}" | tr -d '"')
            if [ -n "${token}" ]; then
              EXTRA+=(--bearer-token "${token}")
            fi
          fi
          python scripts/health_check.py \
            --url "${SMOKE_URL}" \
            --expected-status 200 \
            --retries 5 \
            --timeout 10 \
            --backoff 2 \
            "${EXTRA[@]}"

      - name: Post summary
        run: |
          echo "### Deployed to **prod**" >> $GITHUB_STEP_SUMMARY
          echo "- Tag: \`${{ steps.ver.outputs.tag }}\`" >> $GITHUB_STEP_SUMMARY
          echo "- Registry: \`${{ steps.digests.outputs.registry }}\`" >> $GITHUB_STEP_SUMMARY
          echo "- Analytics digest: \`${{ steps.digests.outputs.analytics_digest }}\`" >> $GITHUB_STEP_SUMMARY
          echo "- AskBeacon digest: \`${{ steps.digests.outputs.askbeacon_digest }}\`" >> $GITHUB_STEP_SUMMARY

      - name: Clean up plan files
        if: always()
        run: rm -f ${{ env.TF_WORKING_DIR }}/tfplan ${{ env.TF_WORKING_DIR }}/tfplan.txt

  no-deploy:
    name: Skip deployment
    needs: changes
    runs-on: ubuntu-latest
    if: needs.changes.outputs.should_run != 'true'
    steps:
      - name: No changes detected
        run: echo "No code or Terraform changes detected. Skipping deployment."

